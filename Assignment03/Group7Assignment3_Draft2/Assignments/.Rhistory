a ->90
a <- 90
100 -> b
a
print(a)
abc = TRUE
class(abc)
marks = c(12,13,14,15,16)
class(marks)
c[1]
marks[1]
marks[marks>13]
marks[marks>13]+2
marks
marks = marks[marks>13]+2
marks
marks[2:5]
marks[c(1,2,3)]
length(marks)
dim(marks)
gradesheet = data.frame(marks,null)
dim(marks)
names = c('a','v','d','e')
dim(names)
marks.2 = c(1,2,3,4)
gradesheet = data.frame(names, marks.2)
gradesheet
dim(gradesheet)
gradesheet$names
View(gradesheet)
names(gradesheet)
group = c(1,1,1,1,2,2,2,3,3)
group
group = as.factor(group)
group
group + 2
groups
group
levels(group)
levels(group) = c("group1","group2","group3")
group
?sort
datamininggrades = c(90,87,69,89,58,93,99,98,76,88)
datamininggrades
sort(datamininggrades)
datamininggrades
sort(x = datamininggrades)
datamininggrades
lettergrade = c("A-", "B+", "F", "B+", "F", "A", "A", "A", "C+", "B+" )
as.factor(lettergrade)
lettergrade
factor(lettergrade)
lettergrade
lettergrade = as.factor(lettergrade)
lettergrade
class(lettergrade)
?factor()
?as.factor()
vector.a = c(1,2,3,4,5,6)
vector.b = c('a','b','c','d','e','f')
cbind(vector.a,vector.b)
matrix.a = cbind(vector.a,vector.b)
matrix.a
class(matrix.a)
data.frame.a = data.frame(vector.a,vector.b)
class(data.frame.a)
data.frame.a
data.frame.a[with(data.frame.a),order(-vector.a)]
data.frame.a[with(data.frame.a),order(-vector.a),]
data.frame.a[with((data.frame.a),order(-vector.a)),]
unemploy_rate = c(7.9,7.7,7.5,7.5,7.5,7.5,7.3,7.2,7.2,7.2,7.0,6.7)
unemploy_rate
length(unemploy_rate)
month = c(‘Jan’, ‘Feb’, ‘Mar’, ‘Apr’, ‘May’, ‘Jun’, ‘Jul’, ‘Aug’, ‘Sep’, ‘Oct’, ‘Nov’, ‘Dec’)
month = c('Jan','Feb','Mar','Apr','May','Jun','July','Aug','Sep','Oct','Sep','Oct','Nov','Dec')
month
length(month)
month = c('Jan','Feb','Mar','Apr','May','Jun','July','Aug','Sep','Oct','Nov','Dec')
length(month)
class(month)
month = as.factor(month)
class(month)
monthly_rate = data.frame(unemploy_rate,month)
class(monthly_rate)
view(monthly_rate)
monthly_rate
monthly_rate$unemploy_rate[monthly_rate$month = 'Mar']
monthly_rate$unemploy_rate[monthly_rate$month == 'Mar']
monthly_rate$month[monthly_rate$unemploy_rate < 7.5]
q()
(123-45)/4 + 4*(72/2.34-3)
abs(-88)
days = c("Monday","Tuesday",Wednesday")
days = c("Monday","Tuesday",Wednesday")
days = c('Monday','Tuesday','Wednesday')
(123-45)/4 + 4*(72/2.34-3)
abs(-88)
log10(72)
e^1.45 - 2.612
exp(1.45) - 2.612
year_born <- 1984
print(year_born)
year_current <- 2014
age = year_current - year_born
age > = 18
age
age >= 18
pi()
?pi
sqrt(100/pi)
pretax.bill <- 45.90
subtotal <- pretax.bill + (8.875/100)*pretax.bill
print(subtotal)
(15/100)*subtotal
(20/100)*subtotal
?importIntoEnv
(81*100)/80
7101/516000
516000/7107
516000/40653
library(readxl)
Optimal_Ordering_Problem <- read_excel("~/Documents/Decision Models/Assignments/Optimal Ordering Problem.xlsx")
View(Optimal_Ordering_Problem)
plot(Forecast,Actual)
attach(Optimal_Ordering_Problem)
plot(Forecast,Actual)
plot(Actual,Forecast)
hist(Forecast,Actual)
hist(Forecast)
?hist()
Error <- Actual - Forecast
Optimal_Ordering_Problem$Error <- Actual - Forecast
library(readxl)
Ord_Problem <- read_excel("~/Documents/Decision Models/Assignments/Optimal Ordering Problem.xlsx")
View(Ord_Problem)
plot(Ord_Problem$Forecast, Ord_Problem$Actual)
cor(Ord_Problem$Forecast, Ord_Problem$Actual)
linearMod <- lm(Ord_Problem$Actual ~ Ord_Problem$Forecast, Ord_Problem)
print(linearMod)
summar(linearMod)
summary(linearMod)
library(tidyverse)
install.packages("tidyverse")
install.packages("ggthemes")
install.packages("ggvis")
install.packages("reshape2")
install.packages("knitr")
install.packages("shiny")
library(readr)
bikesharedailydata <- read_csv("~/Documents/Foundation of Statistics Using R/mydata/bikesharedailydata.csv")
View(bikesharedailydata)
library(readr)
world_internet_usage <- read_csv("~/Documents/Foundation of Statistics Using R/mydata/world_internet_usage.csv")
View(world_internet_usage)
View(swiss)
step(lm(Fertility~Agriculture+Examination+Education+Catholic+Infant.Mortality, data=swiss),direction="backward")
step(lm(Fertility~Agriculture^2+Examination+Education+Catholic+Infant.Mortality, data=swiss),direction="backward")
step(lm(Fertility~Agriculture*Examination+Examination+Education+Catholic+Infant.Mortality, data=swiss),direction="backward")
step(lm(Fertility~Agriculture+Examination+Education+Catholic+Infant.Mortality, data=swiss),direction="forward")
install.packages("glmnet")
library("glmnet")
x=cbind(swiss$Agriculture, swiss$Examination, swiss$Education, swiss$Catholic, swiss$Infant.Mortality)
View(x)
colnames(x, do.NULL = FALSE)colnames(x) = c(”Agriculture”,”Examination”,”Education”, ”Catholic”, ”Infant.Mortality” )
colnames(x, do.NULL = FALSE)
View(x)
colnames(x) = c("Agriculture","Examination","Education", "Catholic", "Infant.Mortality")
View(x)
fit=glmnet(x,swiss$Fertility)
View(fit)
summary(fit)
plot(fit, xvar = "lambda", label = TRUE)
library(readxl)
Cloverleaf <- read_excel("~/Downloads/Cloverleaf.xls")
View(Cloverleaf)
reg = lm(conversionrate ~ brandname + retailer + numberofwords)
reg = lm(Cloverleaf$conversionrate ~ Cloverleaf$brandname + Cloverleaf$retailer + Cloverleaf$numberofwords)
summary(reg)
reg = lm(Cloverleaf$conversionrate ~ Cloverleaf$brandname + Cloverleaf$retailer + Cloverleaf$numberofwords + Cloverleaf$landQuality)
summary(reg)
library(haven)
bh <- read.spss("~/Dropbox/Capstone/Databases/Nepal 2015/bh.sav")
View(bh)
library(foreign)
bh <- read.spss("~/Dropbox/Capstone/Databases/Nepal 2015/bh.sav")
View(bh)
library(haven)
NIhl <- read_sav("~/Dropbox/Capstone/Databases/Niger 2000/NIhl.sav")
View(NIhl)
summary(NIhl)
library(readr)
Data_Extract_From_Health_Nutrition_and_Population_Statistics <- read_csv("~/Dropbox/NYU World Bank Data/Data_Extract_From_Health_Nutrition_and_Population_Statistics.xlsx")
View(Data_Extract_From_Health_Nutrition_and_Population_Statistics)
library(readxl)
Data_Extract_From_Health_Nutrition_and_Population_Statistics <- read_excel("~/Dropbox/NYU World Bank Data/Data_Extract_From_Health_Nutrition_and_Population_Statistics.xlsx")
View(Data_Extract_From_Health_Nutrition_and_Population_Statistics)
library(haven)
bh <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/bh.sav")
View(bh)
library(haven)
ch <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/ch.sav")
View(ch)
library(haven)
bh <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/bh.sav")
View(bh)
library(haven)
hh <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/hh.sav")
View(hh)
library(haven)
hl <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/hl.sav")
View(hl)
library(haven)
wm <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/wm.sav")
View(wm)
View(ch)
View(ch)
View(ch)
View(bh)
summary(bh)
View(ch)
View(ch)
library(haven)
bh <- read_sav("~/Dropbox/Capstone/Databases/Nepal 2015/bh.sav")
View(bh)
install.packages("ROCR")
library("ROCR", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(readr)
truths_prob <- read_csv("~/Documents/Intro to Business Analytics/Assignments/truths_prob.csv")
View(truths_prob)
class(truths_prob)
pred <- prediction(predictions,labels)
pred <- prediction(truths_prob$purchased,truths_prob$`estimated probability of purchase`)
pred <- prediction(truths_prob$purchased,truths_prob$`estimated probability of purchase``)
''
;
pred <- prediction(truths_prob$purchased,truths_prob$`estimated probability of purchase`)
pred <- prediction(truths_prob$`estimated probability of purchase`,truths_prob$purchased)
perf <- performance(pred,"tpr","fpr")
plot(perf)
install.packages("Lift")
install.packages("liftr")
plotlift(truths_prob$`estimated probability of purchase`,truths_prob$purchased,cumulative=TRUE)
plotLift(truths_prob$`estimated probability of purchase`,truths_prob$purchased,cumulative=TRUE)
calibration()?
;
library(readxl)
bigdatadummy1 <- read_excel("~/Downloads/bigdatadummy1.xlsx")
View(bigdatadummy1)
library(readxl)
bigdatadummy2 <- read_excel("~/Downloads/bigdatadummy2.xlsx")
View(bigdatadummy2)
plot(bigdatadummy1)
plot(bigdatadummy1$zip, bigdatadummy1$311)
plot(bigdatadummy1$zip, bigdatadummy1$'311')
plot(bigdatadummy1$zip, bigdatadummy1$`311`)
plot(bigdatadummy1$zip, bigdatadummy1$housing)
library(readxl)
bigdatadummy2 <- read_excel("~/Downloads/bigdatadummy2.xlsx")
View(bigdatadummy2)
ggplot(data = bigdatadummy2, aes(x = bigdatadummy2$month, y = bigdatadummy2$`311`)) +
geom_point()
ggplot2(data = bigdatadummy2, aes(x = bigdatadummy2$month, y = bigdatadummy2$`311`)) +
geom_point()
library("ggvis", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("gplots", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
ggplot2(data = bigdatadummy2, aes(x = bigdatadummy2$month, y = bigdatadummy2$`311`)) +
geom_point()
library(ggplot2)
ggplot2(data = bigdatadummy2, aes(x = bigdatadummy2$month, y = bigdatadummy2$`311`)) +
geom_point()
ggplot(data = bigdatadummy2, aes(x = bigdatadummy2$month, y = bigdatadummy2$`311`)) +
geom_point()
View(bigdatadummy2)
class(bigdatadummy2)
data311 <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$311)
zipv <- data.frame(bigdatadummy2$zip,bigdatadummy2$month)
View(zipv)
housing <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$housing)
311data <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$311)
data311 <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$311)
data311 <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$`311``)
``
data311 <- data.frame(bigdatadummy2$zip,bigdatadummy2$month,bigdatadummy2$`311`)
View(data311)
data311$type = "311data"
housing$type = "housing"
new <- rbind(data311,housing)
View(housing)
library(readxl)
a1_311_housing_cb <- read_excel("~/Desktop/a1_311_housing_cb.xlsx")
View(a1_311_housing_cb)
library(ggvis)
subset(a1_311_housing_cb, numcalls > 2) %>%
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode") %>%
add_axis("y", title = "Number of calls")
library(ggvis)
subset(a1_311_housing_cb, numcalls > 2) %>%
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode") %>%
add_axis("y", title = "Number of calls")
subset(a1_311_housing_cb, numcalls > 2) %>%
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode") %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode") %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
axis = list(stroke = "red", strokeWidth = 5),
grid = list(stroke = "blue"),
ticks = list(stroke = "blue", strokeWidth = 2),
labels = list(angle = 45, align = "left", fontSize = 20)
))
) %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
labels = list(angle = 45, align = "left", fontSize = 20)
)
) %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
labels = list(angle = 90, align = "left", fontSize = 20)
)
) %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
labels = list(angle = 90, align = "left", fontSize = 5)
)
) %>%
add_axis("y", title = "Number of calls")
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
labels = list(angle = 90, align = "left", fontSize = 10)
)
) %>%
add_axis("y", title = "Number of calls")
subset(a1_311_housing_cb, numcalls > 2) %>%
ggvis(a1_311_housing_cb,x=~zip, y=~numcalls) %>%
layer_points(fill = ~source)   %>%
add_axis("x", title = "Zipcode", properties = axis_props(
labels = list(angle = 90, align = "left", fontSize = 10)
)
) %>%
add_axis("y", title = "Number of calls")
/*what*/
library(readxl)
Workbook1 <- read_excel("~/Desktop/Workbook1.xlsx")
View(Workbook1)
sd(Workbook1$A)
sd(Workbook1$B)
library(readxl)
Workbook1 <- read_excel("~/Desktop/Workbook1.xlsx")
View(Workbook1)
sd(Workbook1$A)
pbinom(1,20,0.05)
pnorm(2.57,2.56,0.01) - pnorm(2.53,2.56,0.01)
qnorm(0.9,180,20)
library(readxl)
Workbook1 <- read_excel("~/Desktop/Workbook1.xlsx")
View(Workbook1)
sd(Workbook1$A)
sd(Workbook1$B)
sd(Workbook1$C)
sd(Workbook1$D)
sd(Workbook1$E)
sd(Workbook1$F)
qnorm(0.2,180,20)
knitr::opts_chunk$set(echo = TRUE)
library(DMwR)
library(e1071)
library(performanceEstimation)
library(psych)
library(corrplot)
library(randomForest)
library(DMwR)
library(e1071)
library(performanceEstimation)
library(psych)
library(corrplot)
library(randomForest)
setwd("~/Documents/Module 2/Data Mining in R/Group7Assignment3")
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load('redWine.Rdata')
library(DMwR)
library(e1071)
library(performanceEstimation)
library(psych)
library(corrplot)
library(randomForest)
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load('redWine.Rdata')
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load("redWine.Rdata"")
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load("redWine.Rdata)
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load("redWine.Rdata")
#Working directory
setwd("~../Group7Assignment3")
setwd("../Group7Assignment3")
load('redWine.Rdata')
load('Group7Assignment3/redWine.Rdata')
getwd()
#Working directory
setwd("../Group7Assignment3")
#Load file which is already in R format
load('redWine.Rdata')
sapply(redWine, class) # all numeric save for the objective variable, which is an integer
dev.new(width=10, height=10)
multi.hist(redWine, bcol = "slategray1")
dev.new(width=100, height=100)
multi.hist(redWine, bcol = "slategray1")
load('redWine.Rdata')
ccs <- as.matrix(redWine)
rcorr(ccs, type="pearson")
install.packages("Hmisc") # Only run on first use
library(Hmisc)
ccs <- as.matrix(redWine)
rcorr(ccs, type="pearson")
rcorr(ccs, type="spearman")
logcit <- redWine$citric.acid + 1 # we add one to this variable to prevent errors when logging zeros.
logred <- redWine
logred$citric.acid <- logcit
logred <- log(logred)
logred$quality <- as.numeric(logred$quality)
logred$quality <- round(logred$quality, 1)
library(Hmisc)
ccs <- as.matrix(logred)
rcorr(ccs, type="spearman")
pairs(redWine)
logSample <- sample(1:nrow(logred), size=0.7*nrow(logred))
logred_tr <- logred[logSample,]
logred_ts <- logred[-logSample,]
logsvm_default <- svm(quality ~., logred_tr)
#Get predictions with rounding to the closest integer.
logps1 <- round(predict(logsvm_default, logred_ts),1)
#Results
regr.eval(logred_ts$quality, logps1)
(cm<- table(logps1, logred_ts$quality)) #Need to be careful how we interpret this in the analysis as it looks as if it's a classification problem. It isn't but we do get a rough sense of how the model is performing using it.
x <- logred_tr[,-5]
y <- logred_tr[,5]
log_svm_tune <- tune(svm, quality~., data=logred_tr, train.x=x, train.y=y, ranges=list(cost=1:20, gamma=2^(-1:1)))
summary(log_svm_tune)
svm_tuned <- svm(quality ~., data=logred_tr, cost=6, gamma=0.5)
#Get predictions with rounding to the closest integer.
ps_tune <- predict(svm_tuned, logred_ts)
#Results
regr.eval(logred_ts$quality, ps_tune)
###Visualize Table of Results
(cm<- table(ps_tune, logred_ts$quality)) #Only makes a single prediction!
svm_tuned <- svm(quality ~., data=logred_tr, cost=6, gamma=0.5)
#Get predictions with rounding to the closest integer.
ps_tune <- round(predict(svm_tuned, logred_ts))
#Results
regr.eval(logred_ts$quality, ps_tune)
###Visualize Table of Results
(cm<- table(ps_tune, logred_ts$quality)) #Only makes a single prediction!
svm_tuned <- svm(quality ~., data=logred_tr, cost=6, gamma=0.5)
#Get predictions with rounding to the closest integer.
ps_tune <- predict(svm_tuned, logred_ts)
#Results
regr.eval(logred_ts$quality, ps_tune)
###Visualize Table of Results
(cm<- table(ps_tune, logred_ts$quality)) #Only makes a single prediction!
#Set Seed
set.seed(1234)
#SVM model with linear
log_forest <- randomForest(quality ~., logred_tr, ntree=200)
#Get predictions
log_forest_ps <- round(predict(log_forest, logred_ts),1)
(cm<- table(log_forest_ps, logred_ts$quality))
#Plot error rate
plot(log_forest)
m <- randomForest(quality ~., logred_tr, ntree=200, importance=T)
importance(m)
varImpPlot(m, main="Feature Relevance Scores")
#%IncMSE is a robust and informative measure. It is the increase in MSE of predictions (estimated with out-of-bag-CV) as a result of variable X being permuted (having its values randomly shuffled).
# IncNodePurity: at each split, we can calculate how much this split *reduces* node impurity (for regression trees, indeed, the difference between RSS before and after the split). This is summed over all splits for that variable, over all trees. i.e. how much information gain we get from the variable.
round(cor(logred[,-12], method= 'spearman'),2)
rw <- describe(redWine, IQR=TRUE)
rw
attach(redWine)
barplot((table(round(quality, 1))), col=c("slateblue4", "slategray", "slategray1", "slategray2", "slategray3", "skyblue4"))
mtext("Quality", side=1, outer=F, line=2, cex=0.8)
attach(redWine)
barplot((table(round(quality, 1))), col=c("slateblue4", "slategray", "slategray1", "slategray2", "slategray3", "skyblue4"))
mtext("Quality", side=1, outer=F, line=2, cex=0.8)
